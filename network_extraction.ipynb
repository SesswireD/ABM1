{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from collections import Counter\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "import pickle\n",
    "import cv2\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy.ndimage.measurements\n",
    "import shapely.geometry\n",
    "from PIL import Image\n",
    "from skimage import morphology, segmentation\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import powerlaw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from https://github.com/danvk/extract-raster-network\n",
    "\n",
    "def find_color(im: Image, rgb: Tuple[int]) -> np.ndarray:\n",
    "    \"\"\"Given an RGB image, return an ndarray with 1s where the pixel is the given color.\"\"\"\n",
    "    px = np.asarray(im)\n",
    "    out = np.zeros(im.size, dtype=np.uint8)\n",
    "    r, g, b = rgb\n",
    "    out[(px[:, :, 0] == r) & (px[:, :, 1] == g) & (px[:, :, 2] == b)] = 1\n",
    "    return out\n",
    "\n",
    "\n",
    "def zhang_suen_node_detection(skel: np.ndarray) -> List[Tuple[int]]:\n",
    "    \"\"\"Find nodes based on a skeletonized bitmap.\n",
    "\n",
    "    (From nefi) Node detection based on criteria put forward in \"A fast parallel algorithm\n",
    "    for thinning digital patterns\" by T. Y. Zhang and C. Y. Suen. Pixels p of the skeleton\n",
    "    are categorized as nodes/non-nodes based on the value of a function A(p) depending on\n",
    "    the pixel neighborhood of p. Please check the above paper for details.\n",
    "\n",
    "    A(p1) == 1: The pixel p1 sits at the end of a skeleton line, thus a node\n",
    "    of degree 1 has been found.\n",
    "    A(p1) == 2: The pixel p1 sits in the middle of a skeleton line but not at\n",
    "    a branching point, thus a node of degree 2 has been found. Such nodes are\n",
    "    ignored and not introduced to the graph.\n",
    "    A(p1) >= 3: The pixel p1 belongs to a branching point of a skeleton line,\n",
    "    thus a node of degree >=3 has been found.\n",
    "\n",
    "    Args:\n",
    "        *skel* : Skeletonised source image. The skeleton must be exactly 1 pixel wide.\n",
    "\n",
    "    Returns:\n",
    "        *nodes* : List of (x, y) coordinates of nodes\n",
    "    \"\"\"\n",
    "    skel = np.pad(skel, 1)\n",
    "    item = skel.item\n",
    "\n",
    "    def check_pixel_neighborhood(x, y, skel):\n",
    "        \"\"\"\n",
    "        Check the number of components around a pixel.\n",
    "        If it is either 1 or more than 3, it is a node.\n",
    "        \"\"\"\n",
    "        p2 = item(x - 1, y)\n",
    "        p3 = item(x - 1, y + 1)\n",
    "        p4 = item(x, y + 1)\n",
    "        p5 = item(x + 1, y + 1)\n",
    "        p6 = item(x + 1, y)\n",
    "        p7 = item(x + 1, y - 1)\n",
    "        p8 = item(x, y - 1)\n",
    "        p9 = item(x - 1, y - 1)\n",
    "\n",
    "        # The function A(p1),\n",
    "        # where p1 is the pixel whose neighborhood is beeing checked\n",
    "        components = (\n",
    "            (p2 == 0 and p3 == 1)\n",
    "            + (p3 == 0 and p4 == 1)\n",
    "            + (p4 == 0 and p5 == 1)\n",
    "            + (p5 == 0 and p6 == 1)\n",
    "            + (p6 == 0 and p7 == 1)\n",
    "            + (p7 == 0 and p8 == 1)\n",
    "            + (p8 == 0 and p9 == 1)\n",
    "            + (p9 == 0 and p2 == 1)\n",
    "        )\n",
    "        return (components >= 3) or (components == 1)\n",
    "\n",
    "    nodes = []\n",
    "    w, h = skel.shape\n",
    "    for x in range(1, w - 1):\n",
    "        for y in range(1, h - 1):\n",
    "            if item(x, y) != 0 and check_pixel_neighborhood(x, y, skel):\n",
    "                nodes.append((x - 1, y - 1))\n",
    "    return nodes\n",
    "\n",
    "\n",
    "def find_dense_skeleton_nodes(skel: np.ndarray) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Find \"dense\" (2x2 or larger) regions in the skeleton.\"\"\"\n",
    "    eroded = morphology.binary_erosion(np.pad(skel, 1), np.ones((2, 2)))[1:-1, 1:-1]\n",
    "\n",
    "    # Find the centers of mass of connected components\n",
    "    labeled_array, num_features = scipy.ndimage.measurements.label(eroded)\n",
    "    centers = scipy.ndimage.measurements.center_of_mass(eroded, labeled_array, [*range(1, num_features+1)])\n",
    "    return [(int(x), int(y)) for (x, y) in centers]\n",
    "\n",
    "\n",
    "def add_dense_nodes(nodes: List[Tuple[int, int]], dense_nodes: List[Tuple[int, int]], min_distance = 5) -> List[Tuple[int, int]]:\n",
    "    \"\"\"Add in new nodes which are distinct from the old ones.\"\"\"\n",
    "    keep = []\n",
    "    min_d2 = min_distance ** 2\n",
    "    for node in dense_nodes:\n",
    "        x, y = node\n",
    "        is_ok = True\n",
    "        for nx, ny in nodes:\n",
    "            d2 = (x - nx) **2 + (y - ny) ** 2\n",
    "            if d2 < min_d2:\n",
    "                is_ok = False\n",
    "                break\n",
    "        if is_ok:\n",
    "            keep.append(node)\n",
    "\n",
    "    print(f'Adding {len(keep)}/{len(dense_nodes)} dense nodes to existing {len(nodes)} nodes.')\n",
    "    return [*nodes, *keep]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Path:\n",
    "    start: Tuple[int, int]\n",
    "    stop: Tuple[int, int]\n",
    "    path: List[Tuple[int, int]]\n",
    "\n",
    "\n",
    "def is_new_path(paths: List[Path], path: Path) -> bool:\n",
    "    \"\"\"Is this a new path, or does it overlap signficantly with existing paths?\"\"\"\n",
    "    candidates = [p for p in paths if p.start == path.start and p.stop == path.stop]\n",
    "    other_points = {coord for p in candidates for coord in p.path[1:-1]}\n",
    "    interior = set(path.path[1:-1])\n",
    "    if other_points & interior:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def is_valid_self_loop(path: List[Tuple[int, int]], min_self_loop_distance: int) -> bool:\n",
    "    if len(path) < min_self_loop_distance:\n",
    "        return False\n",
    "    # Only the end node can appear twice in a self-loop\n",
    "    return len([c for c, n in Counter(path).items() if n >= 2]) == 1\n",
    "\n",
    "\n",
    "def find_paths(skel: np.ndarray, nodes: List[Tuple[int]], min_distance=5) -> List[Path]:\n",
    "    \"\"\"Find paths between nodes in the graph using the connectivity in the skeleton.\n",
    "\n",
    "    This returns a list of edges (pairs of nodes) with the following properties.\n",
    "        - path: list of coordinates connecting the nodes (including the nodes)\n",
    "        - d: length of the path\n",
    "\n",
    "    This will early-out if a path shorter than min_distance is found.\n",
    "\n",
    "    There may be multiple distinct paths between the same nodes, or a path between a node and itself.\n",
    "    \"\"\"\n",
    "    width, height = skel.shape\n",
    "\n",
    "    def neighbors(x, y):\n",
    "        for dy in (-1, 0, 1):\n",
    "            cy = y + dy\n",
    "            if cy < 0 or cy >= height:\n",
    "                continue\n",
    "            for dx in (-1, 0, 1):\n",
    "                cx = x + dx\n",
    "                if (dx != 0 or dy != 0) and 0 <= cx < width and skel[cx, cy]:\n",
    "                    yield cx, cy\n",
    "\n",
    "    # each cell points back to its parent\n",
    "    parents = {n: None for n in nodes}\n",
    "\n",
    "    def trace_back(node):\n",
    "        trace = []\n",
    "        while node:\n",
    "            trace.append(node)\n",
    "            node = parents.get(node)\n",
    "        return trace\n",
    "\n",
    "    d = {n: 0 for n in nodes}  # used to avoid backtracking\n",
    "\n",
    "    edges = []\n",
    "    frontier = [*nodes]\n",
    "    while frontier:\n",
    "        next_frontier = []\n",
    "        for n in frontier:\n",
    "            x, y = n\n",
    "            for c in neighbors(x, y):\n",
    "                if c not in parents:\n",
    "                    parents[c] = n\n",
    "                    next_frontier.append(c)\n",
    "                    d[c] = 1 + d[n]\n",
    "                else:\n",
    "                    if d[c] >= d[n]:\n",
    "                        # we've got a connection! Follow both cells back to trace it out\n",
    "                        tn = trace_back(n)\n",
    "                        tc = trace_back(c)\n",
    "                        tc.reverse()\n",
    "                        path = [*tc, *tn]\n",
    "                        endpoints = (path[0], path[-1])\n",
    "                        start, stop = min(endpoints), max(endpoints)\n",
    "                        new_path = Path(start, stop, path)\n",
    "                        # Ignore redundant paths and short self-loops\n",
    "                        if is_new_path(edges, new_path) and (\n",
    "                            start != stop or is_valid_self_loop(path, min_distance)\n",
    "                        ):\n",
    "                            edges.append(new_path)\n",
    "                            if len(path) - 1 < min_distance:\n",
    "                                # This edge will get pruned out anyway, so no need to keep looking.\n",
    "                                return edges\n",
    "\n",
    "        frontier = next_frontier\n",
    "\n",
    "    return edges\n",
    "\n",
    "\n",
    "def merge_nodes(\n",
    "    nodes: List[Tuple[int, int]], edges: List[Path], n1: Tuple[int, int], n2: Tuple[int, int]\n",
    ") -> List[Tuple[int, int]]:\n",
    "    ends = {n1, n2}\n",
    "    paths = [e.path for e in edges if {e.start, e.stop} == ends]\n",
    "    assert paths\n",
    "    path = min(paths, key=lambda p: len(p))\n",
    "    idx = len(path) // 2\n",
    "    new_node = path[idx]\n",
    "    return [new_node] + [n for n in nodes if n != n1 and n != n2]\n",
    "\n",
    "\n",
    "def make_graph(nodes: List[Tuple[int, int]], edges: List[Path]) -> nx.MultiGraph:\n",
    "    g = nx.MultiGraph()\n",
    "    g.add_nodes_from(nodes)\n",
    "    for edge in edges:\n",
    "        g.add_edge(edge.start, edge.stop, path=edge.path, d=len(edge.path) - 1)\n",
    "    return g\n",
    "\n",
    "\n",
    "def connect_graph(skel: np.ndarray, min_distance: int) -> nx.MultiGraph:\n",
    "    \"\"\"Iteratively produce a graph, merging nodes until none are < min_distance apart.\"\"\"\n",
    "    nodes = zhang_suen_node_detection(skel)\n",
    "    dense_nodes = find_dense_skeleton_nodes(skel)\n",
    "    nodes = add_dense_nodes(nodes, dense_nodes)\n",
    "    edges = find_paths(skel, nodes, min_distance)\n",
    "\n",
    "    any_changed = True\n",
    "    while any_changed:\n",
    "        any_changed = False\n",
    "        for edge in edges:\n",
    "            d = len(edge.path) - 1\n",
    "            if d < min_distance:\n",
    "                n1 = edge.start\n",
    "                n2 = edge.stop\n",
    "                nodes = merge_nodes(nodes, edges, n1, n2)\n",
    "                edges = find_paths(skel, nodes, min_distance)\n",
    "                #print(f'Merged {n1} and {n2}, d={d}')\n",
    "                any_changed = True\n",
    "                if n1 == n2:\n",
    "                    any_changed = False\n",
    "                break\n",
    "\n",
    "    # All good!\n",
    "    return make_graph(nodes, edges)\n",
    "\n",
    "\n",
    "def simplify_paths(g: nx.Graph, tolerance=1) -> nx.Graph:\n",
    "    for n1, n2, k in g.edges(keys=True):\n",
    "        g[n1][n2][k]['path'] = shapely.geometry.LineString(g[n1][n2][k]['path']).simplify(tolerance)\n",
    "    return g\n",
    "\n",
    "\n",
    "def extract_network(px: np.ndarray, min_distance=40) -> nx.Graph:\n",
    "    skel = morphology.skeletonize(px)\n",
    "    print(f'Skeleton px={skel.sum()}')\n",
    "    g = connect_graph(skel, min_distance)\n",
    "    g = simplify_paths(g)\n",
    "    return g\n",
    "\n",
    "\n",
    "def create_circular_mask(shape, center, radius):\n",
    "    w, h = shape\n",
    "    cx, cy = center\n",
    "    X, Y = np.ogrid[:w, :h]\n",
    "    dist_from_center = np.sqrt((X - cx) ** 2 + (Y - cy) ** 2)\n",
    "    mask = dist_from_center <= radius\n",
    "    return mask\n",
    "\n",
    "\n",
    "def render_network(im: Image, graph: nx.Graph, rgb: Tuple[int]) -> Image:\n",
    "    \"\"\"Produce a rendering of the extracted street network on top of the image.\n",
    "\n",
    "    Streets (nodes and edges) are colored rgb.\n",
    "    \"\"\"\n",
    "    r, g, b = rgb\n",
    "    px = np.asarray(im).copy()\n",
    "\n",
    "    for x, y in graph.nodes():\n",
    "        circle = create_circular_mask(px.shape[0:2], (y, x), 4).astype(np.uint8)\n",
    "        # clean this up\n",
    "        px[:, :, 0] += r * circle\n",
    "        px[:, :, 1] += g * circle\n",
    "        px[:, :, 2] += b * circle\n",
    "\n",
    "    for (n1, n2, k) in graph.edges(keys=True):\n",
    "        path = graph[n1][n2][k]['path']\n",
    "        for pt1, pt2 in zip([*path.coords][:-1], [*path.coords][1:]):\n",
    "            y1, x1 = pt1\n",
    "            y2, x2 = pt2\n",
    "            cv2.line(px, (int(y1), int(x1)), (int(y2), int(x2)), color=rgb, thickness=1)\n",
    "        for (x, y) in path.coords:\n",
    "            circle = create_circular_mask(px.shape[0:2], (y, x), 2).astype(np.uint8)\n",
    "            px[:, :, 0] += r * circle\n",
    "            px[:, :, 1] += g * circle\n",
    "            px[:, :, 2] += b * circle\n",
    "    return Image.fromarray(px)\n",
    "\n",
    "\n",
    "def render_skeleton(im: Image, skel: np.ndarray, rgb: Tuple[int]) -> Image:\n",
    "    r, g, b = rgb\n",
    "    px = np.asarray(im).copy()\n",
    "    skel = skel.T\n",
    "    px[skel > 0, 0] = r\n",
    "    px[skel > 0, 1] = g\n",
    "    px[skel > 0, 2] = b\n",
    "    return Image.fromarray(px)\n",
    "\n",
    "\n",
    "# Sum of the min & max of (a, b, c)\n",
    "def hilo(a, b, c):\n",
    "    if c < b:\n",
    "        b, c = c, b\n",
    "    if b < a:\n",
    "        a, b = b, a\n",
    "    if c < b:\n",
    "        b, c = c, b\n",
    "    return a + c\n",
    "\n",
    "\n",
    "def complement(rgb):\n",
    "    \"\"\"Return a complementary color; see https://stackoverflow.com/a/40234924/388951\"\"\"\n",
    "    k = hilo(*rgb)\n",
    "    return tuple(k - u for u in rgb)\n",
    "\n",
    "\n",
    "def network_to_geojson(g: nx.Graph):\n",
    "    return {\n",
    "        'type': 'FeatureCollection',\n",
    "        'features': [\n",
    "            {\n",
    "                'type': 'Feature',\n",
    "                'id': f'street-{i}',\n",
    "                'properties': {\n",
    "                    'street': i,\n",
    "                    'len': (e := g[n1][n2][k])['d'],\n",
    "                    'start': (coords := e['path'].coords)[0],\n",
    "                    'stop': coords[-1],\n",
    "                },\n",
    "                'geometry': [*coords],\n",
    "            }\n",
    "            for i, (n1, n2, k) in enumerate(g.edges(keys=True))\n",
    "        ],\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the network and the relevant data from each of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'experiment2' # set the path for the folder that ONLY contains .png files of the networks\n",
    "png_files = os.listdir(folder)\n",
    "rgb = (0,0,0) # rgb define color of networks\n",
    "\n",
    "degree_sequences = []\n",
    "degree_centralities = []\n",
    "\n",
    "# could be parallelized but doesn't take too long and all the data is saved\n",
    "for file in tqdm(png_files):\n",
    "    im = Image.open(folder+'/'+file)\n",
    "    px = find_color(im, rgb).T\n",
    "\n",
    "    # extract the network and adjust the minimum path length if the resulting network is too small (less than 20 nodes)\n",
    "    g = extract_network(px, min_distance=30)\n",
    "    if g.size() < 20:\n",
    "        g = extract_network(px, min_distance=50)\n",
    "        if g.size() < 20:\n",
    "            g = extract_network(px, min_distance=70)\n",
    "\n",
    "\n",
    "\n",
    "    # clean up the graph\n",
    "    G = nx.Graph(g)\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    remove = [node for node, degree in G.degree() if degree < 1]\n",
    "    G.remove_nodes_from(remove)\n",
    "\n",
    "    # get degree distributions and betweenness centrality\n",
    "    degree_sequence = sorted((d for n, d in G.degree()), reverse=True)\n",
    "    degree_sequences.append(degree_sequence)\n",
    "    degree_centrality = nx.betweenness_centrality(G, normalized=False)\n",
    "    degree_centralities.append(degree_centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save betweenness centralities\n",
    "with open('data/betweenness_centrality.pickle', 'wb') as handle:\n",
    "    pickle.dump(degree_centralities, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the degree distributions from the degree sequences and save them to .csv\n",
    "degree_distributions = []\n",
    "\n",
    "for i in range(len(degree_sequences)):\n",
    "    index, values = np.unique(degree_sequences[i], return_counts=True)\n",
    "    values = values\n",
    "    degree_distributions.append(pd.Series(values, index))\n",
    "    # plt.plot(index, values)\n",
    "\n",
    "df = pd.DataFrame(degree_distributions)\n",
    "df.to_csv('data/degree_distributions2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_distributions_normalized = []\n",
    "\n",
    "for i in range(len(degree_sequences)):\n",
    "    index, values = np.unique(degree_sequences[i], return_counts=True)\n",
    "    values = values / len(degree_sequences[i])\n",
    "    degree_distributions_normalized.append(pd.Series(values, index))\n",
    "    # plt.plot(index, values)\n",
    "\n",
    "df = pd.DataFrame(degree_distributions_normalized)\n",
    "df.to_csv('data/degree_distributions_normalized2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dd26d5366d44ebd9f75e801d4379ee901cd05b33c55ee2c3c629088b8d8b0e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
