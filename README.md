# Agent-Based Modeling Group 1
Project for UVA Master course Agent Based Modelling. The model simulates agents walking through a grid from their homes to various locations. The agents leave a trace to comunicate to other agents that they have walked there, and the agents prefer to walk on paths other agents have walked before. The aim of the study was to test if a network emerges and if that network can be used to develop metro-networks.

![](https://github.com/SesswireD/ABM1/blob/main/test_pref_1_seed42.gif)

## Files

The model is based in python 3. 

The file model.py defines the functionality of the model. Here agent classes and their behaviour are defined. The GeoModel class defines how the model is intitialized (creation of agents) and what changes are run in what order.

The file server.py runs the model and visualises it in browser. Adapt this file to change color of the environment or the agents. Add sliders or parameter settings to the model. To start the visualization run the following command in an environment that has all required dependencies installed:

```
python server.py
```

The sensitivity analysis is included in sensitivity_analysis.ipynb. The results can be plotted using figure_plotting.ipynb. The resulting figures of the sensitivity analysis can be found in [figures](https://github.com/SesswireD/ABM1/tree/main/figures). 

The model will produce images. To extract networks from these images network_extraction.ipynb can be used. The experiment that was done on the networks can be found in experiment.ipynb. The images of the experiments done in this study can be found in [Experiment1](https://github.com/SesswireD/ABM1/tree/main/experiment1) and [Experiment2](https://github.com/SesswireD/ABM1/tree/main/experiment2). Experiment 1 contains 30 runs and Experiment 2 contains 100 runs.

[Data map](https://github.com/SesswireD/ABM1/tree/main/data) contains all the data generated by the sensitivity analysis and the experiements. 

## How to use the model 
To run the model with visualization run server.py. The following interface gives you the opportunity to interact with the model:
![](https://github.com/SesswireD/ABM1/blob/main/Commuter_model%20(Mesa%20visualization).png)
The sliders on the left lets you adjust the paramter settings. The slider on top controls the timesteps of the model. When the model starts the agents will move and create an image like shown on this example image.

